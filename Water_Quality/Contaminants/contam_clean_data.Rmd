---
title: "NDFA Contaminants Data: Cleaning"
author: "Dave Bosworth"
date: "8/31/2020"
output: 
  html_document: 
    code_folding: show
    toc: true
    toc_depth: 4
    toc_float: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose

This document provides the code and decisions made to clean and standardize all contaminants data used for the North Delta Flow Action synthesis project. The data were collected by USGS, and includes concentration data for water, suspended sediment, and zooplankton samples. 

Jim Orlando from the USGS provided all of the contaminants data for 2015-2019 in a couple of Excel spreadsheets that are stored on the NDFA SharePoint site. However this dataset provided by Jim Orlando did not include Method Detection Limits (MDL) for each parameter. To obtain the MDL values, we downloaded the contaminants data from the [USGS NWIS website](https://nwis.waterdata.usgs.gov/usa/nwis/qwdata) and added this information to the data provided in the Excel spreadsheets.

# Global code and functions

```{r load packages, message = FALSE, warning = FALSE}
# Load packages
library(tidyverse)
library(readxl)
library(lubridate)
```

```{r load functions}
# Source global WQ functions
source("Water_Quality/global_wq_funcs.R")

# Source contaminants data cleaning functions
source("Water_Quality/Contaminants/contam_clean_data_funcs.R")
```

```{r define file paths}
# Define main NDFA file path for WQ subteam (assumes synced with SharePoint)
fp_fastr <- "California Department of Water Resources/Office of Water Quality and Estuarine Ecology - North Delta Flow Action/WQ_Subteam/"

# Define relative file paths for raw and processed contaminants data files
fp_rel_raw <- paste0(fp_fastr, "Raw_Data/Contaminants")
fp_rel_proc <- paste0(fp_fastr, "Processed_Data/Contaminants")

# Define absolute file paths
fp_abs_raw <- get_abs_path(fp_rel_raw)
fp_abs_proc <- get_abs_path(fp_rel_proc)

# Clean up
rm(fp_rel_raw, fp_rel_proc)

# Create a vector of object names to keep throughout the script
obj_keep <- append(objects(), "obj_keep")
```

The data downloaded from NWIS has 5-digit numeric codes to represent each parameter measured. We developed a crosswalk table to convert these numeric codes to standardized names of the parameters. We also used this crosswalk table to standardize the parameter names in the spreadsheets provided by Jim Orlando.

```{r import param code crosswalk}
# Bring in dataframe to be used as a crosswalk for the parameter codes and standardized names
param_code_cw <- 
  read_excel(
    paste0(fp_abs_raw, "/USGS_Data_Download_metadata.xlsx"), 
    sheet = "Parameter Codes"
  )
```

# Water Concentration Data

## Import Data

```{r import raw water data}
# Import water and suspended sediment concentration data for 2015-2018:
  # Create a vector of all file paths for the raw USGS contaminants data downloaded from NWIS
  nwis_fp <- dir(fp_abs_raw, pattern = "^CONTAM_RAW", full.names = T)
  
  # Import the raw USGS contaminants data downloaded from NWIS
  nwis_orig <-
    tibble(
      sta_code = str_sub(nwis_fp, start = 176, end = -15),
      df = map(nwis_fp, .f = import_nwis_data)
    ) %>% 
    unnest(df)
  
# Split the water and suspended sediment concentration data into separate dataframes
nwis_wc <- nwis_orig %>% filter(medium_cd == "WS")
nwis_ss <- nwis_orig %>% filter(medium_cd == "SS")

# Import water concentration data for 2019:
water_conc19_orig <- 
  read_excel(
    path = paste0(fp_abs_raw, "/2019YoloBypass_Pesticide Results_forDWR.xlsx"),
    sheet =  "Water",
    range = "C1:FS93",
    col_types = c(
      "text",
      rep("skip", 3),
      rep("date", 2),
      rep("skip", 3),
      rep("text", 164)
    )
  )
```

## Clean Data

### Prepare data to be bound

The contaminant water concentration data from 2015-2018 needs to be bound with the 2019 data, but each dataframe needs to be modified to allow for the data to be combined correctly. We'll start with the 2015-2018 data.

#### 2015-2018

There may be a few unnecessary variables in the dataframe with the 2015-2018 water concentrations depending upon the data within them. We'll investigate this further and remove any unnecessary variables.

```{r inspect 2015 to 2018 water df variables}
# Look at unique values for the dqi_cd variable - Data-quality indicator code
unique(nwis_wc$dqi_cd)

# For the dqi_cd variable:
# R = Reviewed and approved
# S = Provisional
# Look at how many values are Provisional
nwis_wc %>% filter(dqi_cd == "S")  # 155 values collected at RD22 on 7/28/2016

# Look at unique values for the rpt_lev_cd variable - Reporting level type
unique(nwis_wc$rpt_lev_cd)

# Look at unique values for the result_lab_cm_tx variable - Lab result comment
unique(nwis_wc$result_lab_cm_tx)
```

We'll remove the medium_cd, dqi_cd and rpt_lev_cd variables since they aren't necessary to keep at this point.

```{r remove variables 2015 to 2018 water df}
nwis_wc_clean1 <- nwis_wc %>% select(-c(medium_cd, dqi_cd, rpt_lev_cd))
```

The 2015-2018 water concentration data downloaded from NWIS has 5-digit numeric codes to represent each parameter measured. We need to convert these numeric codes to the actual names of the parameters. We developed a crosswalk table to help execute this conversion.

```{r import param code crosswalk}
# Bring in dataframe to be used as a crosswalk for the parameter codes
param_code_cw <- 
  read_excel(
    paste0(fp_abs_raw, "/USGS_Data_Download_metadata.xlsx"), 
    sheet = "Parameter Codes"
  )
```

We'll finish preparing the dataframe with the 2015-2018 water concentrations by:

* Parsing the startDateTime variable to a datetime object, separate into two variables for Date and Time
* Converting the numeric parameter codes to the descriptive parameter names
* Adding a Pesticide_type variable
* Creating a new variable to identify estimated values and values above and below the Method Detection Limit (MDL)
* Creating a new variable for the measurement units
* Make the result_va variable equal to its MDL value for the samples below the MDL
* Changing some variable names to standardized names for the NDFA synthesis

```{r finish prep 2015 to 2018 water df}
nwis_wc_clean2 <- nwis_wc_clean1 %>% 
  mutate(
    # parse date-time variable and separate into two variables for Date and Time
    DateTime = ymd_hms(startDateTime, tz = "Etc/GMT+8"),
    Date = as_date(DateTime),
    Time = hms::as_hms(DateTime),
    # create a new variable to identify values above and below the MDL and estimated values
    LabDetect = case_when(
      remark_cd == "<" ~ "Non-detect",
      remark_cd == "E" ~ "Estimated value",
      TRUE ~ "Detect"
    ),
    # create result variable- use MDL values for <MDL data
    Result = if_else(
      LabDetect == "Non-detect",
      rpt_lev_va,
      result_va
    ),
    # create a variable for measurement units
    Units = "ng/L"
  ) %>% 
  # add descriptive parameter names and Pesticide_type variable
  left_join(param_code_cw, by = c("parm_cd" = "parameter_code")) %>% 
  # remove some variables and standardize names
  select(
    StationCode = sta_code,
    Date,
    Time,
    Analyte = parameter_nwis,
    PesticideType = pesticide_type,
    Result,
    LabDetect,
    MDL = rpt_lev_va,
    Units,
    Method = meth_cd,
    LabComments = result_lab_cm_tx
  )
```

## Export Data


# Suspended Sediment Concentration Data

## Import Data

## Clean Data

## Export Data


# Zooplankton Concentration Data

## Import Data

## Clean Data

## Export Data





